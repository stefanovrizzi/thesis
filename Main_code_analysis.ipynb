{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Investigating the relation between energy and information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Work extraction from a generalised Szilard engine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This file contains the code for the main analysis in my thesis. It essentially runs a serial analysis, saving data files from serial analysis in folder called 'polya_images', located within the folder of this script.\n",
    "These simulations compute the average work, the average entropy, the mass probability function and plot the relation between our parameter $\\alpha$ and the average work as $q$ and $N$ change."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import pickle\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def W(k,n,Q): #Work extracted\n",
    "    w = k_b*T*sum([x*np.log(x*Q/n) for x in k if x > 0])\n",
    "    \n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def F(P,n): #F function to compute average entropy\n",
    "    k = np.arange(1, n+1)\n",
    "    f = sum([x*math.log(x, 2.0)*P[x] for x in k])\n",
    "\n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def p(q,N,alpha): # Probability distribution of particles in a given partition\n",
    "\n",
    "    P = [[1],[1-1/q, 1/q]] #initial conditions for N=1\n",
    "\n",
    "    for n in range(1,N):\n",
    "\n",
    "        p_temp = []\n",
    "\n",
    "        pn_0 = P[n][0]*(1-alpha/q) #k=0 for n+1 step\n",
    "        p_temp.extend([pn_0])\n",
    "\n",
    "        for k in range(1,n+1): # 1 <= k <= n\n",
    "            pn_ = P[n][k]*(1-alpha/q-(1-alpha)*k/n) + P[n][k-1]*(alpha/q + (1-alpha)*(k-1)/n)\n",
    "            p_temp.extend([pn_])\n",
    "\n",
    "        k = n+1\n",
    "        pn_n = P[n][k-1]*(alpha/q + (1-alpha)*(k-1)/n)\n",
    "        p_temp.extend([pn_n])\n",
    "\n",
    "        P.append(p_temp)\n",
    "        \n",
    "    return P[N]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialise_batches():\n",
    "    \n",
    "    W_save = [] # batch to save mean work, averaged across trials, for each alpha value\n",
    "    Werr = [] # errorbar\n",
    "    K_save = [] # batch to save mean number of particles across compartments, averaged across trials, for each alpha value\n",
    "\n",
    "    P_save = []\n",
    "    W_save_th = []\n",
    "    \n",
    "    return W_save, Werr, K_save, P_save, W_save_th"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def polya(N, alpha, comp_list_all): # placing particles\n",
    "    \n",
    "    K = np.zeros((N,q)) # initialise vector to store number of particles in each partition during Polya's Urn simulations\n",
    "    comp_list = [] #useful list for random compartment # choice\n",
    "\n",
    "    comp = random.choice(comp_list_all) #random compartment choice for 1st particle\n",
    "    comp_list.append(comp)\n",
    "    K[0, comp] = 1 #place one particle in the 1st chosen compartment at step 0\n",
    "    \n",
    "    for pc in range(1,N): #placement of N particles from n>=2\n",
    "    \n",
    "        if random.random() <= alpha:\n",
    "            comp = random.choice(comp_list_all)\n",
    "\n",
    "        else:\n",
    "            comp = random.choice(comp_list)\n",
    "\n",
    "        comp_list.append(comp)\n",
    "\n",
    "        K[pc, :] = K[pc-1, :] #keep same number of particles for all compartments from previous step\n",
    "        K[pc, comp] = K[pc-1, comp]+1 #add particle to chosen compartment\n",
    "    \n",
    "    return K[-1,:] #keep only last placement arrangement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(trials, N, q, alpha):\n",
    "\n",
    "    K_temp = [] #batch to save number of particles at each trial\n",
    "    W_temp = [] #batch to save extracted work at each trial\n",
    "\n",
    "    for i in range(trials): #multiple trials for each alpha value\n",
    "                \n",
    "        K = polya(N, alpha, comp_list_all) # placing particles and storing their number in vector K\n",
    "\n",
    "        W_temp.append(W(K,N,q)) #computing and saving work W\n",
    "            \n",
    "    return W_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analytical_predictions(q, N, alpha):\n",
    "    \n",
    "    # Probability distribution of particles in a given compartment\n",
    "    P = p(q, N, alpha) #compute\n",
    "    P_save.append(P) #save\n",
    "            \n",
    "    # Average entropy\n",
    "    H_mean = - q/N * F(P,N) + math.log(N, 2.0) #compute\n",
    "            \n",
    "    # Average work extracted\n",
    "    W_mean = - N * k_b * T * np.log(2) * (H_mean - math.log(q, 2.0)) #compute\n",
    "    \n",
    "    return P, W_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def savefile(q, N, W_save_th, W_save, K_save, P_save):\n",
    "    \n",
    "    #Name of files - saving purposes\n",
    "    name_file_ID = \"_q\" + str(q) + \"_N\" + str(N)\n",
    "    folder = 'polya_images/'\n",
    "\n",
    "    #Save With Parameters included in file name\n",
    "    file = [q, N, W_save_th, W_save, K_save, P]\n",
    "\n",
    "    with open(folder+name_file_ID+'.txt', \"wb\") as fp:   # Unpickling\n",
    "        pickle.dump(file, fp)\n",
    "    \n",
    "    return folder, name_file_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def savefigure(Alpha, W_save, Werr, W_save_th, folder, name_file_ID):\n",
    "    \n",
    "    plt.ioff() #avoid showing figures\n",
    "\n",
    "    plt.figure(figsize=(16,8))\n",
    "    plt.errorbar(Alpha, W_save, yerr=Werr, color='k', alpha=.7, label='Simulations')\n",
    "    plt.plot(Alpha, W_save_th, color='r', linewidth=3, label='Prediction')\n",
    "    plt.xlabel(r'$ \\alpha $')\n",
    "    plt.ylabel('-$W (J)$')\n",
    "    plt.legend()\n",
    "    plt.savefig(folder+\"W_alpha\"+name_file_ID+\".png\") # save as png\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Serial analysis: saving data and plots using different $q$ and $N$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Physical constants\n",
    "k_b = 1 #Boltzmann constant\n",
    "T = 1 #Temperature\n",
    "\n",
    "# Parameters for serial analysis\n",
    "compartments = [2, 3, 5, 10, 100, 250, 500, 750, 1000] # number of walls for serial analysis\n",
    "particles = [1, 2, 3, 5, 10, 100, 250, 500, 750, 1000] # total number of particles for serial analysis\n",
    "\n",
    "# Paramteres for Polya's Urn simulations\n",
    "trials = 1000 # trials for each alpha value\n",
    "alpha_res = 51 # number of alpha values between 0 and 1; it determines the resolution of the plots\n",
    "Alpha = np.linspace(0,1,alpha_res) # Polya Urn's parameter ranging between 0 and 1\n",
    "\n",
    "# COMPUTATIONS\n",
    "\n",
    "for idxq, q in enumerate(compartments): # for each number of compartments\n",
    "    \n",
    "    comp_list_all = (np.arange(q)).tolist() #useful list with all the compartment #\n",
    "    \n",
    "    for idxN, N in enumerate(particles): # for each number of particles\n",
    "\n",
    "        # initialise batches\n",
    "        W_save, Werr, K_save, P_save, W_save_th = initialise_batches()\n",
    "        \n",
    "        # POLYA'S URN\n",
    "        for alpha in Alpha: # test different alpha values\n",
    "            \n",
    "            # SIMULATIONS\n",
    "            W_temp = process(trials, N, q, alpha) #compute work for all trials\n",
    "            W_save.append(np.mean(W_temp)) #save mean work\n",
    "            Werr.append(np.std(W_temp)) #save SD\n",
    "            \n",
    "            # ANALYTICAL PREDICTIONS\n",
    "            P, W_mean = analytical_predictions(q, N, alpha)\n",
    "            P_save.append(P), W_save_th.append(W_mean)\n",
    "            \n",
    "        # SAVE FILE\n",
    "        folder, name_file_ID = savefile(q, N, W_save_th, W_save, K_save, P_save)\n",
    "\n",
    "        # SAVE FIGURE\n",
    "        savefigure(Alpha, W_save, Werr, W_save_th, folder, name_file_ID)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
